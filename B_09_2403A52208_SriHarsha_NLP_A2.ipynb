{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdDFqFouE7lEnCOiybEZ0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52208-sudo/NLP/blob/main/B_09_2403A52208_SriHarsha_NLP_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)"
      ],
      "metadata": {
        "id": "wTtSkNVM7JQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing"
      ],
      "metadata": {
        "id": "_RZZlKJHa6wi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYtYsMBB8hn1"
      },
      "outputs": [],
      "source": [
        "simple=\"\"\"The patient is a 56-year-old female with a history of hypertension and type 2 diabetes mellitus. She reports a dull, non-radiating chest pain that worsens with exertion and improves with rest. No associated nausea or vomiting was noted.Blood pressure was 150/90 mmHg, heart rate 88 bpm. Lungs were clear to auscultation. Cardiac examination revealed normal S1 and S2 with no murmurs.Blood pressure was 150/90 mmHg, heart rate 88 bpm. Lungs were clear to auscultation. Cardiac examination revealed normal S1 and S2 with no murmurs.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "839TICsHSDAE",
        "outputId": "0019a7da-5cc7-41a5-d636-e404f7e8a1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The patient is a 56-year-old female with a history of hypertension and type 2 diabetes mellitus. She reports a dull, non-radiating chest pain that worsens with exertion and improves with rest. No associated nausea or vomiting was noted.Blood pressure was 150/90 mmHg, heart rate 88 bpm. Lungs were clear to auscultation. Cardiac examination revealed normal S1 and S2 with no murmurs.Blood pressure was 150/90 mmHg, heart rate 88 bpm. Lungs were clear to auscultation. Cardiac examination revealed normal S1 and S2 with no murmurs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing by word"
      ],
      "metadata": {
        "id": "EmSurjNPbmIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(simple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W0wuHx_SLTX",
        "outputId": "174b7e11-09ea-40d4-8ab8-11ab51a2abc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'a',\n",
              " '56-year-old',\n",
              " 'female',\n",
              " 'with',\n",
              " 'a',\n",
              " 'history',\n",
              " 'of',\n",
              " 'hypertension',\n",
              " 'and',\n",
              " 'type',\n",
              " '2',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " '.',\n",
              " 'She',\n",
              " 'reports',\n",
              " 'a',\n",
              " 'dull',\n",
              " ',',\n",
              " 'non-radiating',\n",
              " 'chest',\n",
              " 'pain',\n",
              " 'that',\n",
              " 'worsens',\n",
              " 'with',\n",
              " 'exertion',\n",
              " 'and',\n",
              " 'improves',\n",
              " 'with',\n",
              " 'rest',\n",
              " '.',\n",
              " 'No',\n",
              " 'associated',\n",
              " 'nausea',\n",
              " 'or',\n",
              " 'vomiting',\n",
              " 'was',\n",
              " 'noted.Blood',\n",
              " 'pressure',\n",
              " 'was',\n",
              " '150/90',\n",
              " 'mmHg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'Lungs',\n",
              " 'were',\n",
              " 'clear',\n",
              " 'to',\n",
              " 'auscultation',\n",
              " '.',\n",
              " 'Cardiac',\n",
              " 'examination',\n",
              " 'revealed',\n",
              " 'normal',\n",
              " 'S1',\n",
              " 'and',\n",
              " 'S2',\n",
              " 'with',\n",
              " 'no',\n",
              " 'murmurs.Blood',\n",
              " 'pressure',\n",
              " 'was',\n",
              " '150/90',\n",
              " 'mmHg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'Lungs',\n",
              " 'were',\n",
              " 'clear',\n",
              " 'to',\n",
              " 'auscultation',\n",
              " '.',\n",
              " 'Cardiac',\n",
              " 'examination',\n",
              " 'revealed',\n",
              " 'normal',\n",
              " 'S1',\n",
              " 'and',\n",
              " 'S2',\n",
              " 'with',\n",
              " 'no',\n",
              " 'murmurs',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing by sentence"
      ],
      "metadata": {
        "id": "l8ThdfuWbshV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LFGS-MYTcJN",
        "outputId": "197a7499-ccbc-4ea1-87bb-57b62571e4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The patient is a 56-year-old female with a history of hypertension and type 2 diabetes mellitus.',\n",
              " 'She reports a dull, non-radiating chest pain that worsens with exertion and improves with rest.',\n",
              " 'No associated nausea or vomiting was noted.Blood pressure was 150/90 mmHg, heart rate 88 bpm.',\n",
              " 'Lungs were clear to auscultation.',\n",
              " 'Cardiac examination revealed normal S1 and S2 with no murmurs.Blood pressure was 150/90 mmHg, heart rate 88 bpm.',\n",
              " 'Lungs were clear to auscultation.',\n",
              " 'Cardiac examination revealed normal S1 and S2 with no murmurs.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering Stop Words"
      ],
      "metadata": {
        "id": "_rXI6Rx1cAo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvDQPB4zTi_C",
        "outputId": "6d5be238-df7b-40d5-cfac-165e9088fe31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(simple)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvIvZEQOT3C4",
        "outputId": "9efc3cb1-9f3b-41e4-e3be-d47e3802ca3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'a',\n",
              " '56-year-old',\n",
              " 'female',\n",
              " 'with',\n",
              " 'a',\n",
              " 'history',\n",
              " 'of',\n",
              " 'hypertension',\n",
              " 'and',\n",
              " 'type',\n",
              " '2',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " '.',\n",
              " 'She',\n",
              " 'reports',\n",
              " 'a',\n",
              " 'dull',\n",
              " ',',\n",
              " 'non-radiating',\n",
              " 'chest',\n",
              " 'pain',\n",
              " 'that',\n",
              " 'worsens',\n",
              " 'with',\n",
              " 'exertion',\n",
              " 'and',\n",
              " 'improves',\n",
              " 'with',\n",
              " 'rest',\n",
              " '.',\n",
              " 'No',\n",
              " 'associated',\n",
              " 'nausea',\n",
              " 'or',\n",
              " 'vomiting',\n",
              " 'was',\n",
              " 'noted.Blood',\n",
              " 'pressure',\n",
              " 'was',\n",
              " '150/90',\n",
              " 'mmHg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'Lungs',\n",
              " 'were',\n",
              " 'clear',\n",
              " 'to',\n",
              " 'auscultation',\n",
              " '.',\n",
              " 'Cardiac',\n",
              " 'examination',\n",
              " 'revealed',\n",
              " 'normal',\n",
              " 'S1',\n",
              " 'and',\n",
              " 'S2',\n",
              " 'with',\n",
              " 'no',\n",
              " 'murmurs.Blood',\n",
              " 'pressure',\n",
              " 'was',\n",
              " '150/90',\n",
              " 'mmHg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'Lungs',\n",
              " 'were',\n",
              " 'clear',\n",
              " 'to',\n",
              " 'auscultation',\n",
              " '.',\n",
              " 'Cardiac',\n",
              " 'examination',\n",
              " 'revealed',\n",
              " 'normal',\n",
              " 'S1',\n",
              " 'and',\n",
              " 'S2',\n",
              " 'with',\n",
              " 'no',\n",
              " 'murmurs',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEmGazLUDTL",
        "outputId": "0ec65c6e-a18c-4362-95f0-3b8497f84fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patient',\n",
              " '56-year-old',\n",
              " 'female',\n",
              " 'history',\n",
              " 'hypertension',\n",
              " 'type',\n",
              " '2',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " '.',\n",
              " 'reports',\n",
              " 'dull',\n",
              " ',',\n",
              " 'non-radiating',\n",
              " 'chest',\n",
              " 'pain',\n",
              " 'worsens',\n",
              " 'exertion',\n",
              " 'improves',\n",
              " 'rest',\n",
              " '.',\n",
              " 'associated',\n",
              " 'nausea',\n",
              " 'vomiting',\n",
              " 'noted.Blood',\n",
              " 'pressure',\n",
              " '150/90',\n",
              " 'mmHg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'Lungs',\n",
              " 'clear',\n",
              " 'auscultation',\n",
              " '.',\n",
              " 'Cardiac',\n",
              " 'examination',\n",
              " 'revealed',\n",
              " 'normal',\n",
              " 'S1',\n",
              " 'S2',\n",
              " 'murmurs.Blood',\n",
              " 'pressure',\n",
              " '150/90',\n",
              " 'mmHg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'Lungs',\n",
              " 'clear',\n",
              " 'auscultation',\n",
              " '.',\n",
              " 'Cardiac',\n",
              " 'examination',\n",
              " 'revealed',\n",
              " 'normal',\n",
              " 'S1',\n",
              " 'S2',\n",
              " 'murmurs',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "HeWz9XKkcU9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(simple)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEPz5J59X7Tj",
        "outputId": "7ec57dd9-bb76-488c-e896-99af34f7d1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'a',\n",
              " '56-year-old',\n",
              " 'femal',\n",
              " 'with',\n",
              " 'a',\n",
              " 'histori',\n",
              " 'of',\n",
              " 'hypertens',\n",
              " 'and',\n",
              " 'type',\n",
              " '2',\n",
              " 'diabet',\n",
              " 'mellitu',\n",
              " '.',\n",
              " 'she',\n",
              " 'report',\n",
              " 'a',\n",
              " 'dull',\n",
              " ',',\n",
              " 'non-radi',\n",
              " 'chest',\n",
              " 'pain',\n",
              " 'that',\n",
              " 'worsen',\n",
              " 'with',\n",
              " 'exert',\n",
              " 'and',\n",
              " 'improv',\n",
              " 'with',\n",
              " 'rest',\n",
              " '.',\n",
              " 'no',\n",
              " 'associ',\n",
              " 'nausea',\n",
              " 'or',\n",
              " 'vomit',\n",
              " 'wa',\n",
              " 'noted.blood',\n",
              " 'pressur',\n",
              " 'wa',\n",
              " '150/90',\n",
              " 'mmhg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'lung',\n",
              " 'were',\n",
              " 'clear',\n",
              " 'to',\n",
              " 'auscult',\n",
              " '.',\n",
              " 'cardiac',\n",
              " 'examin',\n",
              " 'reveal',\n",
              " 'normal',\n",
              " 's1',\n",
              " 'and',\n",
              " 's2',\n",
              " 'with',\n",
              " 'no',\n",
              " 'murmurs.blood',\n",
              " 'pressur',\n",
              " 'wa',\n",
              " '150/90',\n",
              " 'mmhg',\n",
              " ',',\n",
              " 'heart',\n",
              " 'rate',\n",
              " '88',\n",
              " 'bpm',\n",
              " '.',\n",
              " 'lung',\n",
              " 'were',\n",
              " 'clear',\n",
              " 'to',\n",
              " 'auscult',\n",
              " '.',\n",
              " 'cardiac',\n",
              " 'examin',\n",
              " 'reveal',\n",
              " 'normal',\n",
              " 's1',\n",
              " 'and',\n",
              " 's2',\n",
              " 'with',\n",
              " 'no',\n",
              " 'murmur',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understemming\n",
        "Snowball stemmer"
      ],
      "metadata": {
        "id": "gAUntmlHdU1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(simple)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnvhTdn0YSlE",
        "outputId": "99cf8feb-ca2d-4a06-aac1-9718f9372bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "patient ---> patient\n",
            "is ---> is\n",
            "a ---> a\n",
            "56-year-old ---> 56-year-old\n",
            "female ---> femal\n",
            "with ---> with\n",
            "a ---> a\n",
            "history ---> histori\n",
            "of ---> of\n",
            "hypertension ---> hypertens\n",
            "and ---> and\n",
            "type ---> type\n",
            "2 ---> 2\n",
            "diabetes ---> diabet\n",
            "mellitus ---> mellitus\n",
            ". ---> .\n",
            "She ---> she\n",
            "reports ---> report\n",
            "a ---> a\n",
            "dull ---> dull\n",
            ", ---> ,\n",
            "non-radiating ---> non-radi\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            "that ---> that\n",
            "worsens ---> worsen\n",
            "with ---> with\n",
            "exertion ---> exert\n",
            "and ---> and\n",
            "improves ---> improv\n",
            "with ---> with\n",
            "rest ---> rest\n",
            ". ---> .\n",
            "No ---> no\n",
            "associated ---> associ\n",
            "nausea ---> nausea\n",
            "or ---> or\n",
            "vomiting ---> vomit\n",
            "was ---> was\n",
            "noted.Blood ---> noted.blood\n",
            "pressure ---> pressur\n",
            "was ---> was\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmhg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rate\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> lung\n",
            "were ---> were\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscult\n",
            ". ---> .\n",
            "Cardiac ---> cardiac\n",
            "examination ---> examin\n",
            "revealed ---> reveal\n",
            "normal ---> normal\n",
            "S1 ---> s1\n",
            "and ---> and\n",
            "S2 ---> s2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs.Blood ---> murmurs.blood\n",
            "pressure ---> pressur\n",
            "was ---> was\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmhg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rate\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> lung\n",
            "were ---> were\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscult\n",
            ". ---> .\n",
            "Cardiac ---> cardiac\n",
            "examination ---> examin\n",
            "revealed ---> reveal\n",
            "normal ---> normal\n",
            "S1 ---> s1\n",
            "and ---> and\n",
            "S2 ---> s2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs ---> murmur\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(simple)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOT-BklKYmAP",
        "outputId": "d1c0a247-f9cb-4910-87c9-7e7dbb9cbc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "patient ---> paty\n",
            "is ---> is\n",
            "a ---> a\n",
            "56-year-old ---> 56-year-old\n",
            "female ---> fem\n",
            "with ---> with\n",
            "a ---> a\n",
            "history ---> hist\n",
            "of ---> of\n",
            "hypertension ---> hypertend\n",
            "and ---> and\n",
            "type ---> typ\n",
            "2 ---> 2\n",
            "diabetes ---> diabet\n",
            "mellitus ---> mellit\n",
            ". ---> .\n",
            "She ---> she\n",
            "reports ---> report\n",
            "a ---> a\n",
            "dull ---> dul\n",
            ", ---> ,\n",
            "non-radiating ---> non-radiating\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            "that ---> that\n",
            "worsens ---> wors\n",
            "with ---> with\n",
            "exertion ---> exert\n",
            "and ---> and\n",
            "improves ---> improv\n",
            "with ---> with\n",
            "rest ---> rest\n",
            ". ---> .\n",
            "No ---> no\n",
            "associated ---> assocy\n",
            "nausea ---> nause\n",
            "or ---> or\n",
            "vomiting ---> vomit\n",
            "was ---> was\n",
            "noted.Blood ---> noted.blood\n",
            "pressure ---> press\n",
            "was ---> was\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmhg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rat\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> lung\n",
            "were ---> wer\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscult\n",
            ". ---> .\n",
            "Cardiac ---> cardiac\n",
            "examination ---> examin\n",
            "revealed ---> rev\n",
            "normal ---> norm\n",
            "S1 ---> s1\n",
            "and ---> and\n",
            "S2 ---> s2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs.Blood ---> murmurs.blood\n",
            "pressure ---> press\n",
            "was ---> was\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmhg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rat\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> lung\n",
            "were ---> wer\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscult\n",
            ". ---> .\n",
            "Cardiac ---> cardiac\n",
            "examination ---> examin\n",
            "revealed ---> rev\n",
            "normal ---> norm\n",
            "S1 ---> s1\n",
            "and ---> and\n",
            "S2 ---> s2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs ---> murm\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|s|e|able',\n",
        "min=4)\n",
        "words = word_tokenize(simple)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKjXJkzYZFub",
        "outputId": "fbe5e03b-a806-4449-b2f1-68d5fd03fcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "patient ---> paty\n",
            "is ---> is\n",
            "a ---> a\n",
            "56-year-old ---> 56-year-old\n",
            "female ---> fem\n",
            "with ---> with\n",
            "a ---> a\n",
            "history ---> hist\n",
            "of ---> of\n",
            "hypertension ---> hypertend\n",
            "and ---> and\n",
            "type ---> typ\n",
            "2 ---> 2\n",
            "diabetes ---> diabet\n",
            "mellitus ---> mellit\n",
            ". ---> .\n",
            "She ---> she\n",
            "reports ---> report\n",
            "a ---> a\n",
            "dull ---> dul\n",
            ", ---> ,\n",
            "non-radiating ---> non-radiating\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            "that ---> that\n",
            "worsens ---> wors\n",
            "with ---> with\n",
            "exertion ---> exert\n",
            "and ---> and\n",
            "improves ---> improv\n",
            "with ---> with\n",
            "rest ---> rest\n",
            ". ---> .\n",
            "No ---> no\n",
            "associated ---> assocy\n",
            "nausea ---> nause\n",
            "or ---> or\n",
            "vomiting ---> vomit\n",
            "was ---> was\n",
            "noted.Blood ---> noted.blood\n",
            "pressure ---> press\n",
            "was ---> was\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmhg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rat\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> lung\n",
            "were ---> wer\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscult\n",
            ". ---> .\n",
            "Cardiac ---> cardiac\n",
            "examination ---> examin\n",
            "revealed ---> rev\n",
            "normal ---> norm\n",
            "S1 ---> s1\n",
            "and ---> and\n",
            "S2 ---> s2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs.Blood ---> murmurs.blood\n",
            "pressure ---> press\n",
            "was ---> was\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmhg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rat\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> lung\n",
            "were ---> wer\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscult\n",
            ". ---> .\n",
            "Cardiac ---> cardiac\n",
            "examination ---> examin\n",
            "revealed ---> rev\n",
            "normal ---> norm\n",
            "S1 ---> s1\n",
            "and ---> and\n",
            "S2 ---> s2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs ---> murm\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "f7IWw_qfd4r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(simple)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVBXrZUkZ5Rm",
        "outputId": "7a6f0623-9ba7-4cfc-ff2b-3495302e47c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "patient ---> patient\n",
            "is ---> is\n",
            "a ---> a\n",
            "56-year-old ---> 56-year-old\n",
            "female ---> female\n",
            "with ---> with\n",
            "a ---> a\n",
            "history ---> history\n",
            "of ---> of\n",
            "hypertension ---> hypertension\n",
            "and ---> and\n",
            "type ---> type\n",
            "2 ---> 2\n",
            "diabetes ---> diabetes\n",
            "mellitus ---> mellitus\n",
            ". ---> .\n",
            "She ---> She\n",
            "reports ---> report\n",
            "a ---> a\n",
            "dull ---> dull\n",
            ", ---> ,\n",
            "non-radiating ---> non-radiating\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            "that ---> that\n",
            "worsens ---> worsens\n",
            "with ---> with\n",
            "exertion ---> exertion\n",
            "and ---> and\n",
            "improves ---> improves\n",
            "with ---> with\n",
            "rest ---> rest\n",
            ". ---> .\n",
            "No ---> No\n",
            "associated ---> associated\n",
            "nausea ---> nausea\n",
            "or ---> or\n",
            "vomiting ---> vomiting\n",
            "was ---> wa\n",
            "noted.Blood ---> noted.Blood\n",
            "pressure ---> pressure\n",
            "was ---> wa\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmHg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rate\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> Lungs\n",
            "were ---> were\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscultation\n",
            ". ---> .\n",
            "Cardiac ---> Cardiac\n",
            "examination ---> examination\n",
            "revealed ---> revealed\n",
            "normal ---> normal\n",
            "S1 ---> S1\n",
            "and ---> and\n",
            "S2 ---> S2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs.Blood ---> murmurs.Blood\n",
            "pressure ---> pressure\n",
            "was ---> wa\n",
            "150/90 ---> 150/90\n",
            "mmHg ---> mmHg\n",
            ", ---> ,\n",
            "heart ---> heart\n",
            "rate ---> rate\n",
            "88 ---> 88\n",
            "bpm ---> bpm\n",
            ". ---> .\n",
            "Lungs ---> Lungs\n",
            "were ---> were\n",
            "clear ---> clear\n",
            "to ---> to\n",
            "auscultation ---> auscultation\n",
            ". ---> .\n",
            "Cardiac ---> Cardiac\n",
            "examination ---> examination\n",
            "revealed ---> revealed\n",
            "normal ---> normal\n",
            "S1 ---> S1\n",
            "and ---> and\n",
            "S2 ---> S2\n",
            "with ---> with\n",
            "no ---> no\n",
            "murmurs ---> murmur\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)"
      ],
      "metadata": {
        "id": "bNKPY7Vs8OMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub=\"NLP model are transforming the world rapidly!\""
      ],
      "metadata": {
        "id": "q2Yf4Onw7Yyq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing by word"
      ],
      "metadata": {
        "id": "cHei2ZMt785k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9FB0X8u7VIp",
        "outputId": "a0d418e6-caac-43ee-c2b9-a88d4da38e83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP model are transforming the world rapidly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc6HFPxs70gW",
        "outputId": "45343f8e-dbfd-4ee3-ac87-a63f15d36b33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'model', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing by sentence"
      ],
      "metadata": {
        "id": "Vn4cbpgv8upz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiQfMioB8zO8",
        "outputId": "81e10705-f487-487b-d00d-026f4f8fac5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP model are transforming the world rapidly!']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering Stop Words"
      ],
      "metadata": {
        "id": "YrJYaksZ9AmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLbBMxpc83uT",
        "outputId": "02008f87-177f-405a-84ee-ff4e70293d4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(sub)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57IDuZXQ89Gi",
        "outputId": "98825882-d52c-4cd0-be89-799b4eaac8e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'model', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lZr3Zlm9LIc",
        "outputId": "67860a62-5284-44b4-c14a-11557493f5d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'model', 'transforming', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "M_rsYr189q2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(sub)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eWtuiqJ9d91",
        "outputId": "635b4012-f6ae-47c3-8482-68f7ea3a6777"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understemming Snowball stemmer"
      ],
      "metadata": {
        "id": "l3arFl7F97hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(sub)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHDfnUCO-BKX",
        "outputId": "5a94d34b-3cc4-452f-f925-766b8941a336"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "model ---> model\n",
            "are ---> are\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(sub)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h7pL4LL-Gq_",
        "outputId": "9697303e-5b3a-45a2-f508-3c59a8b2123f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "model ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|s|e|able', min=4)\n",
        "words = word_tokenize(sub)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlnNTo4K-Sz4",
        "outputId": "c8861313-0f3a-4328-b57f-7089d08f1f07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "model ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "OcPszblV-7if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(sub)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRt2PvZG-jdz",
        "outputId": "c3e12633-9a24-47dd-d0e4-19326aa8b88b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> NLP\n",
            "model ---> model\n",
            "are ---> are\n",
            "transforming ---> transforming\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapidly\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VY32DVpJ--jm",
        "outputId": "eaf02af4-ab12-4ad0-de9b-3bfbf0283eb3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m2Zpe1Kx_F7F",
        "outputId": "e94e8de9-0364-44ae-a058-1b36108783df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)"
      ],
      "metadata": {
        "id": "oYhRfMan_MUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing"
      ],
      "metadata": {
        "id": "Mz3ICRQB_Qzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\""
      ],
      "metadata": {
        "id": "rzT6z3dp_ha7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XWRzaHR_rNS",
        "outputId": "06c13765-efb7-487f-e6e2-892edcdcc70a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India. \n",
            "It is in 150 acres, with both separate hostel facilities for boys and girls. \n",
            "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing by word"
      ],
      "metadata": {
        "id": "PO5uDkQWAFsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DzuaOzZ_w5h",
        "outputId": "5887babb-f33a-4f9c-ff5f-afdf04cac28a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing by sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "tB3XoRo6AiZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qw91ZOeANSF",
        "outputId": "92b7a2dd-b6f0-483f-abc7-75248738b3e3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.',\n",
              " 'It is in 150 acres, with both separate hostel facilities for boys and girls.',\n",
              " 'There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering Stop Words"
      ],
      "metadata": {
        "id": "-wCNEUn-A50l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYlqRNuxAr7M",
        "outputId": "030d50fc-1ede-4976-e2ee-65bd09c42205"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e143niy6A0zJ",
        "outputId": "17b6bde2-0a6d-42fb-d13c-6d5f524c101d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19EWhvRbA8tB",
        "outputId": "79bf22a5-4d74-496a-df57-4423b8bdf85e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'located',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'boys',\n",
              " 'girls',\n",
              " '.',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "TTsU8eNNBJ0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZCrGu-nBLkj",
        "outputId": "b987a52b-b85e-4412-ff95-7ac4f0f826e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'sr',\n",
              " 'univers',\n",
              " 'campu',\n",
              " 'is',\n",
              " 'locat',\n",
              " 'in',\n",
              " 'ananthasagar',\n",
              " 'villag',\n",
              " 'of',\n",
              " 'hasanparthi',\n",
              " 'mandal',\n",
              " 'in',\n",
              " 'warang',\n",
              " ',',\n",
              " 'telangana',\n",
              " ',',\n",
              " 'india',\n",
              " '.',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acr',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separ',\n",
              " 'hostel',\n",
              " 'facil',\n",
              " 'for',\n",
              " 'boy',\n",
              " 'and',\n",
              " 'girl',\n",
              " '.',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'librari',\n",
              " 'along',\n",
              " 'with',\n",
              " 'india',\n",
              " 'largest',\n",
              " 'technolog',\n",
              " 'busi',\n",
              " 'incub',\n",
              " '(',\n",
              " 'tbi',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'citi',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understemming"
      ],
      "metadata": {
        "id": "ivPGqicMBYcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP7eK0BWBbB5",
        "outputId": "70176878-8984-4d14-b595-2b0a573f76fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> locat\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasagar\n",
            "village ---> villag\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthi\n",
            "Mandal ---> mandal\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangana\n",
            ", ---> ,\n",
            "India ---> india\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separ\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> there\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> librari\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busi\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> citi\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq90vYe3Bjtz",
        "outputId": "9ea928b1-ddb4-4352-d45b-756f63d6c76b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|s|e|able', min=4)\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZu6xU-PBmOx",
        "outputId": "a17ff546-2e71-45c8-d324-3ebc391cf679"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "6CQHUNviCRa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8MDc7AUCTTJ",
        "outputId": "1df6a5d2-4bf3-493e-c2a6-22739dde37fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Telangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> There\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> library\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> Indias\n",
            "largest ---> largest\n",
            "Technology ---> Technology\n",
            "Business ---> Business\n",
            "Incubator ---> Incubator\n",
            "( ---> (\n",
            "TBI ---> TBI\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "a7yW6MuhCWKV",
        "outputId": "03b0757d-f47a-499e-93e1-de19309ca209"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aw9R01fOCYoF",
        "outputId": "e53703a9-5e7a-4d15-8c47-1049d31078e6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}